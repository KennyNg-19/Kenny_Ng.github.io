---
title: datawhale-cv训练营-04模型训练与验证
date: 2020-05-30 18:56:39
tags: [ML, CV]
---





# 模型训练验证与调优

在上一章节我们构建了一个简单的CNN进行训练，但这些还远远不够。一个成熟合格的深度学习训练流程至少具备以下功能：

- 在训练集上进行训练，并**在验证集上进行验证；**
- (模型可以保存最优的权重，并读取权重)
- 记录下训练集和验证集的精度，便于调参。

## 4 模型训练与验证

为此本章将从构建验证集、模型训练和验证、模型保存与加载和模型调参几个部分讲解，在部分小节中将会结合Pytorch代码进行讲解。

## 4.1 学习目标

- 理解验证集的作用，并使用训练集和验证集完成训练
- 学会使用Pytorch环境下的模型读取和加载，并了解调参流程

## 4.2 why构造验证集

在机器学习模型（特别是深度学习模型）的训练过程中，模型是**非常容易过拟合的**——模型在不断的训练过程中训练**误差会逐渐降低**，但<font color="#dd0000">**测试误差的走势**</font>则**不一定**。

在训练过程中，模型只能利用训练数据来进行训练，**并不能接触到测试集上的样本**。因此模型如果将训练集学的<font color="#dd0000">过好，模型就会**记住**<u>训练样本</u>的**细节**，导致模型**在测试集的泛化效果较差**</font>，这种现象称为过拟合（Overfitting）。



过拟合的大致特征，如图所示：随着模型复杂度和模型训练轮数的增加，CNN模型在训练集上的误差会降低，但在测试集上的误差会逐渐降低，然后逐渐升高。

[![IMG](https://github.com/datawhalechina/team-learning/raw/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E8%B7%B5%EF%BC%88%E8%A1%97%E6%99%AF%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%EF%BC%89/IMG/Task04/loss.png)](https://github.com/datawhalechina/team-learning/blob/master/03 计算机视觉/计算机视觉实践（街景字符编码识别）/IMG/Task04/loss.png)





### 导致过拟合的最常见原因

- 最为常见的情况是**模型复杂度（Model Complexity ）太高**，导致模型学习了数据的方方面面——包括**过于细枝末节**的规律。

解决上述问题最好的解决方法：构建一个与测试集<font color="#dd0000">**尽可能分布一致**</font>的验证集，在训练过程中不断验证模型在验证集上的精度，并以此控制模型的训练。



### 何为数据的分布？

这里讨论的**数据的分布**一般指的是<font color="#dd0000">**与标签相关的统计分布**</font>：比如在分类任务中“分布”指的是标签的**类别分布**，训练集-验证集-测试集的**类别分布情况应该大体一致**；如果标签是带有时序信息，则验证集和测试集的时间间隔应该保持一致。



### 验证集主要的2个作用：<font color="#dd0000">验证</font>精度和调整<font color="#dd0000">超参数</font>；

在给定赛题后，赛题方会<u>给定训练集和测试集**两部分**</u>数据。参赛者需要在训练集上面构建模型，并在测试集上面验证模型的泛化能力。

在不提供验证集时，参赛选手可以自己**在本地划分出一个验证集出来**，进行本地验证。训练集、验证集和测试集分别有不同的作用：

- #### 训练集（Train Set）：模型用于训练和调整模型参数；

- #### 验证集（Validation Set）：用来①<font color="#dd0000">验证</font>模型<u>训练后</u>的精度和②调整模型<font color="#dd0000">超参数</font>；

- #### 测试集（Test Set）：验证模型的泛化能力。



因为训练集和验证集是分开的，所以模型在验证集上面的精度**在一定程度上可以反映模型的泛化能力**（前提就是，和测试集分布的一致性）——所以划分时，需要**注意验证集的分布应该与测试集尽量保持一致**。



## 4.3 如何划分 生成验证集

既然验证集这么重要，那么如何划分本地验证集呢：<font color="#dd0000">**从训练集中拆分**</font>一部分得到验证集。

具体的有如下几种方式：

#### 1. 留出法（Hold-Out）——最简单直接的

直接将训练集划分成两部分，新的训练集和验证集。

![](https://tva1.sinaimg.cn/large/007S8ZIlgy1gfapeqhp0gj30r00ee0t0.jpg)

- 这种划分方式的优点是最为直接简单

- 缺点是只得到了一份验证集，有可能导致模型在验证集上过拟合。

- 场景: **数据量比较大**的情况—随机划分，划分得均匀程度的概率更大



#### 2. 交叉验证法（Cross Validation，CV）

将训练集划分成K份，将其中的K-1份作为训练集，剩余的1份作为验证集，循环K训练。

![](https://tva1.sinaimg.cn/large/007S8ZIlgy1gfapfbvkqkj30qg0huaaj.jpg)

这种划分方式是**所有的训练集<font color="#dd0000">都做过一次验证集</font>**，最终模型验证精度是K份平均得到。

- 优点: 验证集<font color="#dd0000">**精度比较可靠（所有训练数据都做过验证集）**</font>，训练K次可以得到K个有多样性差异的模型；
- 缺点: 需要训练K次，加大了训练的量（epoch）
- 场景：不适合**数据量很大**的情况——那样划分的频率过高



#### 3. 自助采样法（BootStrap）(略)

通过**有放回**的**采样方式**得到新的训练集和验证集，每次的训练集和验证集都是有区别的。

![](https://tva1.sinaimg.cn/large/007S8ZIlgy1gfapje5ph0j30q40ew74p.jpg)

- 场景：数据量较小



#### 实际使用时的选择

这些划分方法是**从数据划分方式的角度**来讲的，在现有的数据比赛中**一般采用**的划分方法是**<font color="#dd0000">留出法和交叉验证法</font>**



## 5. 模型调优流程

深度学习原理少但实践性非常强，基本上很多的模型的验证只能通过训练来完成。同时深度学习有**众多的网络结构和超参数**，因此需要反复尝试需要较多的训练时间。而如何有效的训练深度学习模型逐渐成为了一门学问。

### 5.1 训练技巧

深度学习有众多的训练技巧，本节挑选了常见的一些技巧来讲解，并针对本次赛题进行具体分析。



与传统的机器学习模型不同，深度学习模型的精度与模型的**复杂度、数据量、正则化、数据扩增等因素**直接相关。

所以当深度学习模型处于不同的阶段（欠拟合、过拟合和完美拟合）的情况下，大家可以知道可以什么角度来继续优化模型。



在参加本次比赛的过程中，我建议大家以如下逻辑完成：

- 1.初步构建简单的CNN模型，不用特别复杂，跑通训练、验证和预测的流程；
- 2.此时简单CNN模型的损失会比较大，尝试**增加模型复杂度**，并观察验证集精度；
- 3.在增加模型复杂度的**同时增加数据扩增方法**，<font color="#dd0000">直至**验证集精度不变**</font>。



对应如下图

![IMG](https://github.com/datawhalechina/team-learning/raw/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E8%B7%B5%EF%BC%88%E8%A1%97%E6%99%AF%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%EF%BC%89/IMG/Task04/%E8%B0%83%E5%8F%82%E6%B5%81%E7%A8%8B.png)