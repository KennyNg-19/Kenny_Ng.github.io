<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>池中之物</title>
  
  <subtitle>By Kenny_Ng</subtitle>
  <link href="/Kenny_Ng.github.io/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-05-25T17:04:51.031Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Kenny Ng</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hexo指令的使用和经历的坑</title>
    <link href="http://yoursite.com/2020/05/26/hexo%E6%8C%87%E4%BB%A4%E4%BD%BF%E7%94%A8%E7%BB%8F%E5%8E%86/"/>
    <id>http://yoursite.com/2020/05/26/hexo%E6%8C%87%E4%BB%A4%E4%BD%BF%E7%94%A8%E7%BB%8F%E5%8E%86/</id>
    <published>2020-05-26T04:52:21.000Z</published>
    <updated>2020-05-25T17:04:51.031Z</updated>
    
    <content type="html"><![CDATA[<p>（为了防止自己忘记，而万一有下一次，所以当日记记下）</p><p><a href="https://hexo.io/zh-cn/docs/commands.html" target="_blank" rel="noopener">官网中文解说</a></p><h2 id="亲历-用Hexo命令解决搭建博客的坑"><a href="#亲历-用Hexo命令解决搭建博客的坑" class="headerlink" title="亲历: 用Hexo命令解决搭建博客的坑"></a>亲历: 用Hexo命令解决搭建博客的<font color="#dd0000">坑</font></h2><h3 id="1-hexo-clean"><a href="#1-hexo-clean" class="headerlink" title="1. hexo clean"></a>1. hexo clean</h3><p>清除缓存文件 (<code>db.json</code>) 和<strong>已生成的静态文件 (<code>public</code>)</strong>——就是hexo d<strong>推送到GitHub并显示到前端的<font color="#dd0000">网页静态源码</font></strong>。</p><p><strong>Case</strong>: 在某些情况（尤其是<strong>编辑过主题后</strong>）， 如果发现您<strong>对站点的<font color="#dd0000">更改无论如何也不生效</font>——因为<code>hexo g</code>并<u>不会</u>将全本地的<font color="#dd0000">生成的静态文件</font>和<font color="#dd0000">现有的<code>public</code></font>路径的文件<font color="#dd0000">一一对比，而是部分对比</font>，来更新后者</strong>——此时，可能需要运行该命令<strong>重新生成网页源码</strong>。</p><h3 id="2"><a href="#2" class="headerlink" title="2."></a>2.</h3><p>to be coninue…</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;（为了防止自己忘记，而万一有下一次，所以当日记记下）&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://hexo.io/zh-cn/docs/commands.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官网中文解说&lt;/a&gt;&lt;/p&gt;
&lt;h2 id
      
    
    </summary>
    
    
    
      <category term="走过的坑" scheme="http://yoursite.com/tags/%E8%B5%B0%E8%BF%87%E7%9A%84%E5%9D%91/"/>
    
  </entry>
  
  <entry>
    <title>datawhale-cv训练营-03字符识别模型</title>
    <link href="http://yoursite.com/2020/05/26/datawhale-cv03%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B/"/>
    <id>http://yoursite.com/2020/05/26/datawhale-cv03%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B/</id>
    <published>2020-05-25T17:24:13.000Z</published>
    <updated>2020-05-26T16:08:30.975Z</updated>
    
    <content type="html"><![CDATA[<p>前面的章节，我们讲解了赛题的背景知识和赛题数据的读取。 本文的任务是: 基于对赛题理解本章将构建一个定长多字符分类模型, 构建一个<strong>CNN类</strong>的定长字符识别模型。</p><h2 id="3-字符识别模型"><a href="#3-字符识别模型" class="headerlink" title="3 字符识别模型"></a>3 字符识别模型</h2><p>本章将会讲解卷积神经网络（Convolutional Neural Network, CNN）的常见层，并从头搭建一个字符识别模型。</p><h3 id="3-1-学习目标"><a href="#3-1-学习目标" class="headerlink" title="3.1 学习目标"></a>3.1 学习目标</h3><ul><li>学习CNN基础和原理</li><li>使用Pytorch框架构建CNN模型，并完成训练</li></ul><h3 id="3-2-CNN介绍"><a href="#3-2-CNN介绍" class="headerlink" title="3.2 CNN介绍"></a>3.2 CNN介绍</h3><p>卷积神经网络（简称CNN）是一类特殊的人工神经网络，是深度学习中重要的一个分支。</p><h4 id="为什么CV方面用CNN？"><a href="#为什么CV方面用CNN？" class="headerlink" title="为什么CV方面用CNN？"></a>为什么CV方面用CNN？</h4><p>CNN在很多领域都表现优异，精度和速度比传统计算学习算法高很多。<strong>特别是在计算机视觉领域</strong>，CNN是解决图像分类、图像检索、物体检测和语义分割的主流模型。</p><h4 id="常见结构组成"><a href="#常见结构组成" class="headerlink" title="常见结构组成"></a>常见结构组成</h4><p>CNN每一层由众多的卷积核组成，每个卷积核对输入的像素进行<strong>卷积操作</strong>，得到下一次的输入。随着网络层的增加卷积核会逐渐扩大感受野，并缩减图像的尺寸。</p><p>CNN是一种<u><strong>层次</strong></u>模型: </p><h5 id="1-Input"><a href="#1-Input" class="headerlink" title="1. Input"></a>1. Input</h5><p>输入的是原始的<strong>像素数据</strong>。</p><h5 id="2-中间处理计算"><a href="#2-中间处理计算" class="headerlink" title="2. 中间处理计算"></a>2. 中间处理计算</h5><p>CNN通过<strong>卷积（convolution）、池化（pooling）、<u>非线性</u>激活函数（non-linear activation function）和全连接层（fully connected layer）</strong>构成。</p><p><img src="https://github.com/datawhalechina/team-learning/raw/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E8%B7%B5%EF%BC%88%E8%A1%97%E6%99%AF%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%EF%BC%89/IMG/Task03/%E5%8D%B7%E7%A7%AF.png" alt="卷积过程"></p><h5 id="3-Output"><a href="#3-Output" class="headerlink" title="3. Output"></a>3. Output</h5><p>通过多次卷积和池化，CNN的<strong>最后一层将输入的图像像素映射为具体的输出</strong>：如在分类任务中会转换为不同类别的<strong>概率输出</strong>，</p><h5 id="4-学习过程-优化参数-——反向传播"><a href="#4-学习过程-优化参数-——反向传播" class="headerlink" title="4. 学习过程(优化参数)——反向传播"></a>4. 学习过程(优化参数)——反向传播</h5><p>然后计算真实标签与CNN模型的输出的预测结果的<strong>差异</strong>，并通过<strong>反向传播更新每层的参数</strong>；在更新完成<strong>后再次前向传播</strong>，如此反复直到训练完成 。</p><p><img src="https://github.com/datawhalechina/team-learning/raw/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E8%B7%B5%EF%BC%88%E8%A1%97%E6%99%AF%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%EF%BC%89/IMG/Task03/Le_CNN.png" alt="经典的字符识别模型"></p><h3 id="3-3-模型的优势特点"><a href="#3-3-模型的优势特点" class="headerlink" title="3.3 模型的优势特点"></a>3.3 模型的优势特点</h3><p>传统机器学习相比，CNN, 或者说<font color="#dd0000"><strong>深度学习模型</strong>(各种<strong><u>深度神经网络</u></strong>)</font>，具有一种<strong><font color="#dd0000">端到端（End to End）的优势</font></strong>：模型训练的过程中是<strong><font color="#dd0000">直接</font></strong>从<u>输入</u>图像像素到<u>最终的输出</u>分类结果——<font color="#dd0000">并<strong>不涉及</strong>到具体的<strong>特征提取</strong>和构建模型的过程</font>，也不需要<strong>人工的</strong>参与。</p><h3 id="3-4-实战：Pytorch构建CNN模型"><a href="#3-4-实战：Pytorch构建CNN模型" class="headerlink" title="3.4 实战：Pytorch构建CNN模型"></a>3.4 实战：Pytorch构建CNN模型</h3><p>在Pytorch中构建CNN模型非常简单，<strong>只需要定义</strong>好模型的<strong>参数</strong>和<strong>正向传播函数</strong>即可，<font color="#dd0000">Pytorch会根据正向传播<strong>自动计算反向传播</strong></font>！！</p><h4 id="1-定义模型"><a href="#1-定义模型" class="headerlink" title="1. 定义模型"></a>1. 定义模型</h4><pre class=" language-Python"><code class="language-Python"># 定义模型: 这个CNN模型包括两个卷积层，最后并联6个全连接层进行分类class SVHN_Model1(nn.Module):    # 构造器：1. 只需要定义好模型参数    def __init__(self):        super(SVHN_Model1, self).__init__()        # CNN提取特征模块        self.cnn = nn.Sequential(            nn.Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2)),            nn.ReLU(),              nn.MaxPool2d(2),            nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2)),            nn.ReLU(),             nn.MaxPool2d(2),        )        #         self.fc1 = nn.Linear(32*3*7, 11)        self.fc2 = nn.Linear(32*3*7, 11)        self.fc3 = nn.Linear(32*3*7, 11)        self.fc4 = nn.Linear(32*3*7, 11)        self.fc5 = nn.Linear(32*3*7, 11)        self.fc6 = nn.Linear(32*3*7, 11)        # 2. 只需要定义好模型正向传播即可，Pytorch会根据正向传播自动计算反向传播。    def forward(self, img):                feat = self.cnn(img)        feat = feat.view(feat.shape[0], -1)        c1 = self.fc1(feat)        c2 = self.fc2(feat)        c3 = self.fc3(feat)        c4 = self.fc4(feat)        c5 = self.fc5(feat)        c6 = self.fc6(feat)        return c1, c2, c3, c4, c5, c6# 构造一个模型对象model = SVHN_Model1()</code></pre><h4 id="2-使用模型"><a href="#2-使用模型" class="headerlink" title="2. 使用模型"></a>2. 使用模型</h4><p>在训练之前，需要定义好</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 损失函数</span>criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 优化器</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0.005</span><span class="token punctuation">)</span></code></pre><p>然后就是训练： 过程包括，Pytorch<strong>自动计算</strong>反向传播，让模型真正的实现<font color="#dd0000">“<strong>自我学习</strong>”</font></p><pre class=" language-python"><code class="language-python">loss_plot<span class="token punctuation">,</span> c0_plot <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 迭代10个Epoch</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>        c0<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> c3<span class="token punctuation">,</span> c4<span class="token punctuation">,</span> c5 <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>c0<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> \                criterion<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> \                criterion<span class="token punctuation">(</span>c2<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> \                criterion<span class="token punctuation">(</span>c3<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> \                criterion<span class="token punctuation">(</span>c4<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> \                criterion<span class="token punctuation">(</span>c5<span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        loss <span class="token operator">/=</span> <span class="token number">6</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss_plot<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        c0_plot<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>c0<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> data<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">1.0</span> <span class="token operator">/</span> c0<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span></code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;前面的章节，我们讲解了赛题的背景知识和赛题数据的读取。 本文的任务是: 基于对赛题理解本章将构建一个定长多字符分类模型, 构建一个&lt;strong&gt;CNN类&lt;/strong&gt;的定长字符识别模型。&lt;/p&gt;
&lt;h2 id=&quot;3-字符识别模型&quot;&gt;&lt;a href=&quot;#3-字符识别模型
      
    
    </summary>
    
    
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
      <category term="CV" scheme="http://yoursite.com/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>datawhale-cv训练营-02数据读取与数据扩增</title>
    <link href="http://yoursite.com/2020/05/23/datawhale-cv02/"/>
    <id>http://yoursite.com/2020/05/23/datawhale-cv02/</id>
    <published>2020-05-23T04:39:17.000Z</published>
    <updated>2020-05-23T13:52:38.634Z</updated>
    
    <content type="html"><![CDATA[<p>在上一章节，官方提供了三种不同的解决方案。从本章开始 将逐渐的学习使用<strong>【定长字符识别】思路</strong>来构建模型，讲解赛题的解决方案和相应知识点。</p><h2 id="2-数据读取与数据扩增"><a href="#2-数据读取与数据扩增" class="headerlink" title="2 数据读取与数据扩增"></a>2 数据读取与数据扩增</h2><h3 id="2-1-学习目标"><a href="#2-1-学习目标" class="headerlink" title="2.1 学习目标"></a>2.1 学习目标</h3><p>本章主要内容为<strong>图像数据读取、数据扩增方法</strong>和<strong>实战Pytorch读取赛题数据</strong>三个部分组成。</p><ul><li>学习Python和Pytorch中图像读取</li><li>学会扩增方法和实战Pytorch读取赛题数据</li></ul><h3 id="2-2-图像读取"><a href="#2-2-图像读取" class="headerlink" title="2.2 图像读取"></a>2.2 图像读取</h3><p>在识别之前，首先需要完成<strong>对数据的读取操作</strong>。在Python中有很多库可以完成数据读取的操作，比较常见的有<strong>Pillow和OpenCV</strong>。</p><h4 id="2-2-1-Pillow"><a href="#2-2-1-Pillow" class="headerlink" title="2.2.1 Pillow"></a>2.2.1 Pillow</h4><p>Pillow是Python图像<strong>处理函式库(PIL）</strong>的一个分支。Pillow提供了常见的图像读取和处理的操作。</p><h4 id="2-2-2-OpenCV"><a href="#2-2-2-OpenCV" class="headerlink" title="2.2.2 OpenCV"></a>2.2.2 OpenCV</h4><p>OpenCV是一个跨平台的<strong>计算机视觉库</strong>。OpenCV发展的非常早，拥有<strong>众多的计算机视觉、数字图像处理和机器视觉等功能</strong>。OpenCV在功能上<font color="#dd0000"><strong>比Pillow更加强大很多，但学习成本也高很多</strong></font>。</p><h3 id="2-3-数据扩增"><a href="#2-3-数据扩增" class="headerlink" title="2.3 数据扩增"></a>2.3 数据扩增</h3><p>现在回到赛题街道字符识别任务中。在赛题中我们需要对的图像进行字符识别，因此需要我们完成的数据的读取操作，同时也需要完成<strong>数据扩增（Data Augmentation）操作</strong>。</p><h4 id="2-3-1-基本介绍"><a href="#2-3-1-基本介绍" class="headerlink" title="2.3.1 基本介绍"></a>2.3.1 基本介绍</h4><p>在深度学习中数据扩增方法非常重要，数据扩增可以增加训练集的样本，同时也可以有效缓解模型过拟合的情况，也可以给模型带来的更强的泛化能力。</p><p>已知，在深度学习模型的训练过程中，数据扩增是<font color="#dd0000">必不可少的环节</font>。</p><ul><li><h4 id="数据扩增为什么有用？"><a href="#数据扩增为什么有用？" class="headerlink" title="数据扩增为什么有用？"></a><font color="#dd0000">数据扩增为什么有用？</font></h4></li></ul><ol><li><p>现有深度学习的参数非常多，一般的模型可训练的<font color="#dd0000"><strong>参数量基本上都是万到百万级别，而训练集样本的数量很难有这么多</strong></font>。</p></li><li><p>其次数据扩增可以<font color="#dd0000"> <strong>扩展样本空间</strong></font>：假设现在的分类模型需要对汽车进行分类</p><p>如果<strong>不使用任何数据扩增方法</strong>，深度学习模型会<strong>从汽车车头的角度❌</strong>来进行判别，<strong>而不是汽车具体的区别✅</strong>。</p></li></ol><p><img src="https://github.com/datawhalechina/team-learning/raw/master/03%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E5%AE%9E%E8%B7%B5%EF%BC%88%E8%A1%97%E6%99%AF%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%E8%AF%86%E5%88%AB%EF%BC%89/IMG/Task02/%E6%95%B0%E6%8D%AE%E6%89%A9%E5%A2%9Ecar.png" alt="汽车分类"></p><h4 id="2-3-2-常见的数据扩增方法"><a href="#2-3-2-常见的数据扩增方法" class="headerlink" title="2.3.2 常见的数据扩增方法"></a>2.3.2 常见的数据扩增方法</h4><ul><li><h4 id="有哪些数据扩增方法？"><a href="#有哪些数据扩增方法？" class="headerlink" title="有哪些数据扩增方法？"></a>有哪些数据扩增方法？</h4></li></ul><p>数据扩增方法有很多：<font color="#dd0000">从<strong>颜色空间、尺度空间到样本空间</strong>，同时根据不同任务数据扩增都有相应的区别</font>。</p><blockquote><p>对于图像分类，数据扩增一般<font color="#dd0000"><strong>不会改变标签</strong></font>;(即本比赛的<strong>需求</strong>场景)</p><p>对于物体检测，数据扩增会改变物体坐标位置；</p><p>对于图像分割，数据扩增会改变像素标签。</p></blockquote><p><strong>Note</strong>: 在本次赛题中，赛题任务是需要对图像中的字符进行识别，因此对于<strong><font color="#dd0000">字符图片并不能进行翻转操作</font>。比如字符6经过水平翻转就变成了字符9</strong>，<font color="#dd0000"><strong>会改变字符原本的含义</strong></font></p><ul><li><h4 id="具体常用的方法和数据扩增库"><a href="#具体常用的方法和数据扩增库" class="headerlink" title="具体常用的方法和数据扩增库"></a><strong>具体</strong>常用的方法和数据扩增<u>库</u></h4></li></ul><p>在常见的数据扩增方法中，一般会从<strong>图像颜色、尺寸、形态、空间和像素等角度</strong>进行变换。当然不同的数据扩增方法可以自由进行组合，得到更加丰富的数据扩增方法。</p><p>以<strong><a href="https://pytorch.org/docs/stable/torchvision/index.html" target="_blank" rel="noopener">torchvision</a></strong>(pytorch官方提供的数据扩增库，提供了基本的数据数据扩增方法，可以<u>无缝与torch进行集成</u>；但<u>数据扩增方法种类较少，且速度中等</u>)为例，常见的数据扩增方法（API）包括：</p><pre class=" language-python"><code class="language-python"><span class="token operator">-</span> transforms<span class="token punctuation">.</span>CenterCrop 对图片中心进行裁剪<span class="token operator">-</span> transforms<span class="token punctuation">.</span>ColorJitter 对图像颜色的对比度、饱和度和零度进行变换<span class="token operator">-</span> transforms<span class="token punctuation">.</span>FiveCrop 对图像四个角和中心进行裁剪得到五分图像<span class="token operator">-</span> transforms<span class="token punctuation">.</span>Grayscale 对图像进行灰度变换<span class="token operator">-</span> transforms<span class="token punctuation">.</span>Pad 使用固定值进行像素填充<span class="token operator">-</span> transforms<span class="token punctuation">.</span>RandomAffine 随机仿射变换<span class="token operator">-</span> transforms<span class="token punctuation">.</span>RandomCrop 随机区域裁剪<span class="token operator">-</span> transforms<span class="token punctuation">.</span>RandomHorizontalFlip 随机水平翻转<span class="token operator">-</span> transforms<span class="token punctuation">.</span>RandomRotation 随机旋转<span class="token operator">-</span> transforms<span class="token punctuation">.</span>RandomVerticalFlip 随机垂直翻转</code></pre><p>除了torchvision，还有速度<strong>更快的第三方扩增库</strong>供选择：</p><ol><li><p><a href="https://github.com/aleju/imgaug" target="_blank" rel="noopener">imgaug</a> 提供了多样的数据扩增方法，且组合起来非常方便，速度较快；</p></li><li><p><a href="https://albumentations.readthedocs.io" target="_blank" rel="noopener">albumentations</a> 提供了多样的数据扩增方法，对图像分类、语义分割、物体检测和关键点检测都支持，速度较快。</p></li></ol><h2 id="2-4-Pytorch读取数据"><a href="#2-4-Pytorch读取数据" class="headerlink" title="2.4 Pytorch读取数据"></a>2.4 Pytorch读取数据</h2><p>由于本次赛题我们使用Pytorch框架讲解具体的解决方案，接下来将是解决赛题的<strong>第一步</strong>使用<strong>Pytorch读取赛题数据</strong>。</p><h4 id="2-4-1-一些定义-写代码前想好大致逻辑"><a href="#2-4-1-一些定义-写代码前想好大致逻辑" class="headerlink" title="2.4.1 一些定义(写代码前想好大致逻辑)"></a>2.4.1 一些定义(写代码前想好大致逻辑)</h4><p>首先，<strong>区分</strong>Dataset和DataLoder这两个<u>数据处理的常用术语</u> 和 <strong>解释</strong>有了Dataset为什么还要有DataLoder？</p><p>其实这两个是两个不同的概念，是为了<strong>实现不同的功能</strong>。</p><ul><li>Dataset：对<font color="#dd0000"><strong>数据集的封装</strong></font>，提供索引方式的对数据样本进行读取</li><li>DataLoder：对<font color="#dd0000"><strong>Dataset进行封装</strong></font>，提供批量读取的迭代读取</li></ul><p>而<font color="#dd0000"><strong>在Pytorch中的数据读取逻辑</strong></font>， 数据①先<strong>通过Dataset进行封装</strong>，②再<u><strong>通过DataLoder进行并行读取</strong></u>。</p><h4 id="2-4-2-代码"><a href="#2-4-2-代码" class="headerlink" title="2.4.2 代码"></a>2.4.2 代码</h4><h5 id="Step①定义对数据集封装的Dataset-详情，见注释"><a href="#Step①定义对数据集封装的Dataset-详情，见注释" class="headerlink" title="Step①定义对数据集封装的Dataset(详情，见注释)"></a>Step①定义对数据集封装的Dataset(详情，见注释)</h5><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 省略各种import </span><span class="token keyword">class</span> <span class="token class-name">SVHNDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token comment" spellcheck="true"># constructor</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img_path<span class="token punctuation">,</span> img_label<span class="token punctuation">,</span> transform<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>img_path <span class="token operator">=</span> img_path        self<span class="token punctuation">.</span>img_label <span class="token operator">=</span> img_label         <span class="token keyword">if</span> transform <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>transform <span class="token operator">=</span> None    <span class="token comment" spellcheck="true"># getter: 因为Dataset是提供【索引方式】的对数据样本进行读取</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        img <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_path<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>transform <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            img <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 原始SVHN中类别10为数字0</span>        lbl <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_label<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int<span class="token punctuation">)</span>        lbl <span class="token operator">=</span> list<span class="token punctuation">(</span>lbl<span class="token punctuation">)</span>  <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">5</span> <span class="token operator">-</span> len<span class="token punctuation">(</span>lbl<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> img<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>lbl<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_path<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 获取: 图片数据和label的路径</span>train_path <span class="token operator">=</span> glob<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">'../input/train/*.png'</span><span class="token punctuation">)</span>train_path<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token punctuation">)</span>train_json <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>open<span class="token punctuation">(</span><span class="token string">'../input/train.json'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>train_label <span class="token operator">=</span> <span class="token punctuation">[</span>train_json<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'label'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> train_json<span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 定义数据集实例</span>data <span class="token operator">=</span> SVHNDataset<span class="token punctuation">(</span>train_path<span class="token punctuation">,</span> train_label<span class="token punctuation">,</span>          transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>              <span class="token comment" spellcheck="true"># 缩放到固定尺寸</span>              transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token comment" spellcheck="true">########################## 数据扩增 ##########################</span>              <span class="token comment" spellcheck="true"># 随机颜色变换</span>              transforms<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>              <span class="token comment" spellcheck="true"># 加入随机旋转</span>              transforms<span class="token punctuation">.</span>RandomRotation<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>              <span class="token comment" spellcheck="true"># 将图片转换为pytorch 的tesntor</span>              transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>              <span class="token comment" spellcheck="true"># 对图像像素进行归一化</span>                            transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span><span class="token number">0.456</span><span class="token punctuation">,</span><span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span><span class="token number">0.224</span><span class="token punctuation">,</span><span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><h5 id="Step②定义对Dataset封装的DataLoader"><a href="#Step②定义对Dataset封装的DataLoader" class="headerlink" title="Step②定义对Dataset封装的DataLoader"></a>Step②定义对Dataset封装的DataLoader</h5><p>加入DataLoder：数据按照<strong>批次(batch_size=10)</strong>获取，每批次调用Dataset读取单个样本进行拼接。</p><p>此时data的格式为：<code>torch.Size([10, 3, 64, 128]), torch.Size([10, 6])</code>。</p><p>前者为图像文件，为batchsize * chanel * height * width次序；后者为字符标签。</p><pre class=" language-python"><code class="language-python">train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>data<span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 封装上面的dataset即可</span>    batch_size<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 每批样本个数</span>    shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 是否打乱顺序</span>    num_workers<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token comment" spellcheck="true"># 读取的线程个数</span><span class="token punctuation">)</span><span class="token keyword">for</span> data <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 后续操作...</span></code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在上一章节，官方提供了三种不同的解决方案。从本章开始 将逐渐的学习使用&lt;strong&gt;【定长字符识别】思路&lt;/strong&gt;来构建模型，讲解赛题的解决方案和相应知识点。&lt;/p&gt;
&lt;h2 id=&quot;2-数据读取与数据扩增&quot;&gt;&lt;a href=&quot;#2-数据读取与数据扩增&quot; clas
      
    
    </summary>
    
    
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
      <category term="CV" scheme="http://yoursite.com/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>datawhale-cv训练营-01赛题研究</title>
    <link href="http://yoursite.com/2020/05/19/datawhale-cv01/"/>
    <id>http://yoursite.com/2020/05/19/datawhale-cv01/</id>
    <published>2020-05-18T16:53:16.000Z</published>
    <updated>2020-05-23T10:45:24.082Z</updated>
    
    <content type="html"><![CDATA[<p>这次<strong>基础</strong>赛事, 是Datawhale与天池联合发起的零基础<strong>入门系列</strong>赛事 <a href="https://tianchi.aliyun.com/competition/entrance/531795/introduction" target="_blank" rel="noopener">赛事地址</a></p><h1 id="本文目的"><a href="#本文目的" class="headerlink" title="本文目的"></a>本文目的</h1><ol><li><strong>总结</strong>基本了解比赛规则</li><li><strong>总结</strong>解题思路</li><li>数据下载和<strong>理解</strong></li></ol><h1 id="1-规则"><a href="#1-规则" class="headerlink" title="1.规则"></a>1.规则</h1><p>本赛题需要选手识别图片中所有的字符。<strong>评测指标</strong>：准确率，Score=编码识别正确的数量/测试集图片数量</p><p>为了降低比赛难度，我们提供了训练集、验证集中所有字符的<strong>位置框</strong>（在<strong>阿里天池</strong>上下载）。</p><p><strong>注意</strong>: 按照比赛规则，所有的参赛选手，<strong>只能使用比赛给定的数据集完成训练(不要使用SVHN原始数据集进行训练</strong>）</p><h4 id="使用的Python模块"><a href="#使用的Python模块" class="headerlink" title="使用的Python模块"></a>使用的Python模块</h4><p>大概介绍一下，这里可能需要用到的主要模块。</p><blockquote><p>numpy ：提供了python对多维数组对象的支持：ndarray，具有矢量运算能力，快速、节省空间。numpy支持高级大量的维度数组与矩阵运算，此外也针对数组运算提供大量的数学函数库。</p><p>torch：神经网络界的 Numpy, 因为他能将 torch 产生的 tensor 放在 GPU 中加速运算 (前提是你有合适的 GPU), 就像 Numpy 会把 array 放在 CPU 中加速运算. 所以神经网络的话, 当然是用 Torch 的 tensor 形式数据最好</p><p>torchvision：torchvision包是服务于pytorch深度学习框架的,用来生成图片,视频数据集,和一些流行的模型类和预训练模型。我认为这个是最关键的模块</p><p>OpenCV（import时候是cv2）：一款强大的跨平台的计算机视觉库，使用它能完成我们对于图像和视频处理的很多功能。它以电信号的方式加以捕捉、记录、处理、储存、传送与重现的各种技术。这里主要是用来对图片的处理</p><p>json：这个就是json的读写库，处理json文件的</p></blockquote><h1 id="2-数据理解"><a href="#2-数据理解" class="headerlink" title="2. 数据理解"></a>2. 数据理解</h1><h4 id="数据集初步观察"><a href="#数据集初步观察" class="headerlink" title="数据集初步观察"></a>数据集初步观察</h4><p>分.json的label位置信息，和原图集合</p><p><strong>数据读取</strong>： json文件包含的位置信息，除了便于正式的训练，还可以用于数据观察——直接作用在原图集，<strong>查看已给的位置信息的分割效果</strong></p><p>样例代码: 数据读取，在此我们给出JSON中标签的读取方式</p><pre><code>import jsontrain_json = json.load(open(&#39;../input/train.json&#39;))# 数据标注处理def parse_json(d):   arr = np.array([       d[&#39;top&#39;], d[&#39;height&#39;], d[&#39;left&#39;],  d[&#39;width&#39;], d[&#39;label&#39;]   ])   arr = arr.astype(int)   return arrimg = cv2.imread(&#39;../input/train/000000.png&#39;)arr = parse_json(train_json[&#39;000000.png&#39;])plt.figure(figsize=(10, 10))plt.subplot(1, arr.shape[1]+1, 1)plt.imshow(img)plt.xticks([]); plt.yticks([])for idx in range(arr.shape[1]):   plt.subplot(1, arr.shape[1]+1, idx+2)   plt.imshow(img[arr[0, idx]:arr[0, idx]+arr[1, idx],arr[2, idx]:arr[2, idx]+arr[3, idx]])   plt.title(arr[4, idx])   plt.xticks([]); plt.yticks([])</code></pre><p>输出</p><p><a href="https://tva1.sinaimg.cn/large/007S8ZIlgy1gez59nbvuij30z30u0gtm.jpg" target="_blank" rel="noopener"><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gez59nbvuij30z30u0gtm.jpg" alt="img"></a></p><p><a href="https://tva1.sinaimg.cn/large/007S8ZIlgy1gez5ab60sij30yw0oaqc0.jpg" target="_blank" rel="noopener"><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gez5ab60sij30yw0oaqc0.jpg" alt="img"></a></p><h1 id="3-潜在的疑难杂症"><a href="#3-潜在的疑难杂症" class="headerlink" title="3. 潜在的疑难杂症"></a>3. 潜在的疑难杂症</h1><h4 id="预处理细节"><a href="#预处理细节" class="headerlink" title="预处理细节"></a>预处理细节</h4><p>数据集存在原图片<strong>大小不统一</strong>，这个只需要用pytorch的transforms处理即可</p><h4 id="难点"><a href="#难点" class="headerlink" title="难点"></a>难点</h4><h5 id="a-确定待识别数字在图中的位置"><a href="#a-确定待识别数字在图中的位置" class="headerlink" title="a.确定待识别数字在图中的位置"></a>a.确定待识别数字在图中的位置</h5><p>(使用比赛简化后的数据，则该问题并不存在了)</p><p>在简化数据集之前的难点是：模型要能找到待识别数字的<strong>位置</strong>。但是既然处理后的数据集，<strong>位置信息全都提供了</strong>，那么这个问题就容易很多——<strong>单纯的识别数字信息</strong>。数字的位数问题可以通过简单的算法来解决，就像MNIST数据集一样。</p><p><a href="https://crazy-winds.github.io/images/cv1/0-1.png" target="_blank" rel="noopener"><img src="https://crazy-winds.github.io/images/cv1/0-1.png" alt="图1"></a>图1</p><p>（json格式存储label和位置信息）</p><p><a href="https://crazy-winds.github.io/images/cv1/0-2.png" target="_blank" rel="noopener"><img src="https://crazy-winds.github.io/images/cv1/0-2.png" alt="图2"></a>图2</p><h5 id="b-确定待识别数字的个数"><a href="#b-确定待识别数字的个数" class="headerlink" title="b.确定待识别数字的个数"></a>b.确定待识别数字的个数</h5><p>即每幅图的数字个数可能均不相同，如何统一的解决(找到一种general的方法)</p><p>将在解题思路部分详细展开</p><h1 id="4-大致解题思路"><a href="#4-大致解题思路" class="headerlink" title="4. 大致解题思路"></a>4. 大致解题思路</h1><ol><li>简单入门思路：定长字符识别。将不定长字符转化为定长处理，不足部分用<strong>填充占位符</strong>为代替</li></ol><p>（<strong>适合新手</strong>也<strong>适合此题给的处理后的数据集</strong>：赛题数据集中大部分图像中字符个数为2-4个，最多的字符 个数为<strong>6个</strong>）</p><p><a href="https://crazy-winds.github.io/images/cv1/0-3.png" target="_blank" rel="noopener"><img src="https://crazy-winds.github.io/images/cv1/0-3.png" alt="图3"></a>图3</p><ol><li>专业字符识别思路：按照<strong>不定长字符</strong>处理</li></ol><p>在字符识别研究中，有<strong>特定的方法</strong>来解决此种不定长的字符识别问题：如<strong>典型的有CRNN字符识别模型</strong>。</p><p>因为本次赛题中给定的图像数据都<strong>比较规整，可以视为一个单词或者一个句子</strong> 喂进CRNN模型。</p><ol><li>专业分类思路：检测位置再识别数字</li></ol><p>在赛题数据中已经给出了训练集、验证集中所有图片中字符的位置，因此可以首先将字符的位置进行识别，利用<strong>物体检测</strong>的思路完成。</p><p>可参考物体检测模型：<strong>SSD或者YOLO</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这次&lt;strong&gt;基础&lt;/strong&gt;赛事, 是Datawhale与天池联合发起的零基础&lt;strong&gt;入门系列&lt;/strong&gt;赛事 &lt;a href=&quot;https://tianchi.aliyun.com/competition/entrance/531795/int
      
    
    </summary>
    
    
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
      <category term="CV" scheme="http://yoursite.com/tags/CV/"/>
    
  </entry>
  
  <entry>
    <title>NLP-intro</title>
    <link href="http://yoursite.com/2020/02/29/NLP-intro/"/>
    <id>http://yoursite.com/2020/02/29/NLP-intro/</id>
    <published>2020-02-29T05:30:38.000Z</published>
    <updated>2020-05-29T11:03:23.579Z</updated>
    
    <content type="html"><![CDATA[<h2 id="0-NLP的研究方向"><a href="#0-NLP的研究方向" class="headerlink" title="0. NLP的研究方向"></a>0. NLP的研究方向</h2><p>2个大方向对应了，语言的<strong>“一进一出”</strong></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gf99ljg3ooj30v80hswh7.jpg" alt=""></p><h2 id="1-NLU之机器翻译"><a href="#1-NLU之机器翻译" class="headerlink" title="1. NLU之机器翻译"></a>1. NLU之机器翻译</h2><h2 id="思路a-暴力法"><a href="#思路a-暴力法" class="headerlink" title="思路a: 暴力法"></a>思路a: 暴力法</h2><h3 id="原理：全排列组合分词后的句子，用语言模型从中筛选出语义最合适的"><a href="#原理：全排列组合分词后的句子，用语言模型从中筛选出语义最合适的" class="headerlink" title="原理：全排列组合分词后的句子，用语言模型从中筛选出语义最合适的"></a>原理：<strong>全排列组合</strong>分词后的句子，用语言模型从中筛选出语义最合适的</h3><p>第一步通过<strong>翻译模型TM</strong>进行<strong>分词</strong></p><p>第二步映射词语，因为语法的存在而进行<u>映射后词语的排列组合</u></p><p>第三步通过<strong>语言模型LM</strong>选出排列组合中最合适的语句</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gf99soj3vmj317w0kuq8d.jpg" alt="">缺点: 排列组合的复杂度太高</p><p>解决: <strong>维特比Viterbi</strong>算法——<strong>同时考虑TM</strong>分词+<strong>LM筛选</strong>这分开2个步骤</p><h2 id="思路b-维特比Viterbi算法"><a href="#思路b-维特比Viterbi算法" class="headerlink" title="思路b: 维特比Viterbi算法"></a>思路b: <strong>维特比Viterbi</strong>算法</h2><h3 id="原理：贝叶斯TM和LM"><a href="#原理：贝叶斯TM和LM" class="headerlink" title="原理：贝叶斯TM和LM"></a>原理：贝叶斯TM和LM</h3><p><strong>串联TM</strong>分词+<strong>LM筛选</strong>这分开的2个步骤</p><h3 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h3><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gf9i9qd3wlj31680f20vt.jpg" alt="流程图"></p><p>各个部分的作用</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gf9iup3gr2j30x20icwjg.jpg" alt="">好处：降低了复杂度，<strong>避免了原来随机排列组合生成句子</strong>的<strong>NP-hard的指数级</strong>复杂度</p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gf9iao2h3fj309802e749.jpg" alt=""></p><h4 id="1-语言模型LM"><a href="#1-语言模型LM" class="headerlink" title="1. 语言模型LM"></a>1. 语言模型LM</h4><h5 id="作用：生成句子-即输出"><a href="#作用：生成句子-即输出" class="headerlink" title="作用：生成句子(即输出)"></a>作用：生成句子(即输出)</h5><h5 id="分类：按照当前生成的语言，对之前词语的”记忆“程度"><a href="#分类：按照当前生成的语言，对之前词语的”记忆“程度" class="headerlink" title="分类：按照当前生成的语言，对之前词语的”记忆“程度"></a>分类：按照当前生成的语言，对之前词语的”记忆“程度</h5><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gf9i640a7bj316e0aojut.jpg" alt=""></p><p>Unigram model, Bingram model …. n-gram model</p><p>至于每个Prop, 则¨源于提前的计算(概率统计)</p><h5 id="性能标准"><a href="#性能标准" class="headerlink" title="性能标准"></a>性能标准</h5><p>生成之后同时看Prop，句子<strong>错误少</strong>的<strong>概率应该越大</strong></p><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gf9iknu2qsj30yw06idh3.jpg" alt=""></p><h4 id="2-翻译模型TM"><a href="#2-翻译模型TM" class="headerlink" title="2. 翻译模型TM"></a>2. 翻译模型TM</h4><h6 id=""><a href="#" class="headerlink" title=""></a></h6>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;0-NLP的研究方向&quot;&gt;&lt;a href=&quot;#0-NLP的研究方向&quot; class=&quot;headerlink&quot; title=&quot;0. NLP的研究方向&quot;&gt;&lt;/a&gt;0. NLP的研究方向&lt;/h2&gt;&lt;p&gt;2个大方向对应了，语言的&lt;strong&gt;“一进一出”&lt;/strong&gt;&lt;
      
    
    </summary>
    
    
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
      <category term="NLP" scheme="http://yoursite.com/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Pytorch一些小细节补充</title>
    <link href="http://yoursite.com/2019/08/26/sum_pytorch_details/"/>
    <id>http://yoursite.com/2019/08/26/sum_pytorch_details/</id>
    <published>2019-08-26T08:32:47.000Z</published>
    <updated>2020-05-26T09:05:12.724Z</updated>
    
    <content type="html"><![CDATA[<h1 id="补充Pytorch中的易被忽视但得注意的细节"><a href="#补充Pytorch中的易被忽视但得注意的细节" class="headerlink" title="补充Pytorch中的易被忽视但得注意的细节"></a>补充Pytorch中的易被忽视但得注意的细节</h1><h4 id="1-定义Dataloader的num-workers参数"><a href="#1-定义Dataloader的num-workers参数" class="headerlink" title="1. 定义Dataloader的num_workers参数"></a>1. 定义Dataloader的num_workers参数</h4><p><strong>Q</strong>: </p><p>在给Dataloader设置worker数量（<code>num_worker</code>）时，到底<strong>设置多少合适</strong>？这个worker到底怎么工作的？<br><strong>如果将<code>num_worker</code>设为0（也是默认值），就没有worker了吗？</strong></p><p><strong>A</strong>: <code>num_workers</code>的经验设置值<strong>是<font color="#dd0000">自己电脑/服务器的CPU核心数</font></strong>，(比如我的Macbook Pro16寸是 6核)如果CPU很强+配的<strong>RAM是充足的</strong>，就可以设置为<strong>略微≥核心数</strong>。</p><ol><li><p>参数的<strong>作用</strong>： 官方注释为：</p><blockquote><p> how many <strong>subprocesses</strong> to use for data loading.</p><p> <code>0</code> means that the data will be loaded <strong>in the main process.</strong> (default: <code>0</code>)</p></blockquote><p>作用：denotes the <strong><font color="#dd0000">number of processes that generate batches in parallel</font></strong> to generate your data <font color="#dd0000"><strong>on multiple cores</strong> in real time</font></p><p>详细解释：每每轮到dataloader加载数据时：</p><pre class=" language-python"><code class="language-python"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span>start_epoch<span class="token punctuation">,</span> end_epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> data <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>trainloader<span class="token punctuation">)</span><span class="token punctuation">:</span></code></pre><p>dataloader<strong>一次性创建<code>num_worker</code>个worker</strong>，（也可以说dataloader一次性创建<code>num_worker</code>个工作进程，worker也是普通的工作进程），并用<code>batch_sampler</code>将指定batch分配给指定worker，worker将它负责的batch加载进RAM。</p><p>然后，dataloader从RAM中找本轮迭代要用的batch，如果找到了，就使用。如果没找到，就要<code>num_worker</code>个worker继续加载batch到内存，直到dataloader在RAM中找到目标batch。一般情况下都是能找到的，因为<code>batch_sampler</code>指定batch时当然优先指定本轮要用的batch。</p></li><li><p><strong>不同赋值时各自的意义</strong>：<code>num_worker</code>设置得大，好处是<strong>寻batch速度快</strong>，因为下一轮迭代的batch很可能在上一轮/上上一轮…迭代时已经加载好了。坏处是<strong>内存开销大</strong>，也加重了CPU负担（worker加载数据到RAM的进程是CPU复制的嘛）。</p><p>如果设为0，意味着每一轮迭代时，dataloader<strong>不再有自主加载数据到RAM</strong>这一步骤（因为没有worker了），而是在RAM中找batch，找不到时再加载相应的batch。缺点当然是<strong>速度更慢</strong>。</p></li></ol><h4 id="2"><a href="#2" class="headerlink" title="2."></a>2.</h4>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;补充Pytorch中的易被忽视但得注意的细节&quot;&gt;&lt;a href=&quot;#补充Pytorch中的易被忽视但得注意的细节&quot; class=&quot;headerlink&quot; title=&quot;补充Pytorch中的易被忽视但得注意的细节&quot;&gt;&lt;/a&gt;补充Pytorch中的易被忽视但得注意的
      
    
    </summary>
    
    
    
      <category term="ML" scheme="http://yoursite.com/tags/ML/"/>
    
  </entry>
  
</feed>
