<!DOCTYPE HTML>
<html lang="zh-CNs">


<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta name="keywords" content="DeepLearning.ai新课-NLP-Course1, 池中之物">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>DeepLearning.ai新课-NLP-Course1 | 池中之物</title>
    <link rel="icon" type="image/png" href="/Kenny_Ng.github.io/favicon.png">

    <link rel="stylesheet" type="text/css" href="/Kenny_Ng.github.io/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/Kenny_Ng.github.io/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/Kenny_Ng.github.io/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/Kenny_Ng.github.io/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/Kenny_Ng.github.io/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/Kenny_Ng.github.io/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/Kenny_Ng.github.io/css/my.css">

    <script src="/Kenny_Ng.github.io/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 4.2.1"><link rel="alternate" href="/Kenny_Ng.github.io/atom.xml" title="池中之物" type="application/atom+xml">
<link rel="stylesheet" href="/Kenny_Ng.github.io/css/prism-tomorrow.css" type="text/css"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>


<body>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/Kenny_Ng.github.io/" class="waves-effect waves-light">
                    
                    <img src="/Kenny_Ng.github.io/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">池中之物</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Kenny_Ng.github.io/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Kenny_Ng.github.io/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Kenny_Ng.github.io/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Kenny_Ng.github.io/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Kenny_Ng.github.io/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Kenny_Ng.github.io/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/Kenny_Ng.github.io/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/Kenny_Ng.github.io/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">池中之物</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/Kenny_Ng.github.io/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Kenny_Ng.github.io/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Kenny_Ng.github.io/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Kenny_Ng.github.io/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Kenny_Ng.github.io/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Kenny_Ng.github.io/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/Kenny_Ng.github.io/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/Kenny_Ng.github.io/medias/featureimages/0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">DeepLearning.ai新课-NLP-Course1</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/Kenny_Ng.github.io/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/Kenny_Ng.github.io/tags/NLP/">
                                <span class="chip bg-color">NLP</span>
                            </a>
                        
                            <a href="/Kenny_Ng.github.io/tags/math/">
                                <span class="chip bg-color">math</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2020-08-08
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>Update Date:&nbsp;&nbsp;
                    2020-08-16
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    2.7k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>Read Times:&nbsp;&nbsp;
                    12 Min
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="1-Task-text-classification"><a href="#1-Task-text-classification" class="headerlink" title="1. Task: text classification"></a>1. Task: text classification</h1><h2 id="法1-Logsitc回归模型"><a href="#法1-Logsitc回归模型" class="headerlink" title="法1: Logsitc回归模型"></a>法1: Logsitc回归模型</h2><h2 id="法2-纯靠词频的Naive-Bayes模型"><a href="#法2-纯靠词频的Naive-Bayes模型" class="headerlink" title="法2: 纯靠词频的Naive Bayes模型"></a>法2: 纯靠词频的Naive Bayes模型</h2><blockquote>
<p>Naive Bayes is an example of <strong>supervised machine learnin</strong>g, and shares <strong>many similarities with the logistic regression</strong> method </p>
</blockquote>
<h3 id="Why-Naive-单纯地靠词频-→-概率"><a href="#Why-Naive-单纯地靠词频-→-概率" class="headerlink" title="Why Naive? 单纯地靠词频 → 概率"></a><font color="#dd0000">Why Naive? 单纯地靠词频 → 概率</font></h3><p>this method makes the assumption that <strong>the features(比如  句中的词前后是有关系的，或者说有某些词总是常见伴随出现的，这些相关性会影响词频) you’re using for classification are <u>all independent</u></strong>, which in reality is <strong>rarely the case</strong>.</p>
<h4 id="不足-Naive-的2个理想前提"><a href="#不足-Naive-的2个理想前提" class="headerlink" title="(不足)Naive 的2个理想前提"></a>(不足)Naive 的2个理想前提</h4><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghmww5z78ej30z607kq58.jpg" alt="2个assumption" style="zoom:33%;" />

<h5 id="1-忽视本身多个词的关联性"><a href="#1-忽视本身多个词的关联性" class="headerlink" title="1. 忽视本身多个词的关联性"></a>1. 忽视本身多个词的关联性</h5><p>Some words <strong>①often appear together</strong> and/or they might also <strong>②be related to the thing they’re always describing</strong>. </p>
<p>These words in a sentence are not always necessarily independent of one another, but <strong>Naive Bayes assumes that they are</strong>. This could lead you to <strong><font color="#dd0000">under or over estimates the conditional probabilities of individual word</font>——一般把常常一起出现的词，当做互相独立，更多是<u>underestimate</u>它们的条件概率</strong>. Naive Bayes <strong>might assign equal probability to all words</strong> even though <strong>from the context</strong> you can see that one of them <strong>is the most likely candidate</strong>. </p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghmx4bziloj31a207qjxg.jpg" style="zoom:50%;" />



<h5 id="2-各个类比例不均匀分布的原始数据集-distribution-of-the-training-data-sets"><a href="#2-各个类比例不均匀分布的原始数据集-distribution-of-the-training-data-sets" class="headerlink" title="2. 各个类比例不均匀分布的原始数据集 distribution of the training data sets"></a>2. 各个类比例不均匀分布的原始数据集 distribution of the training data sets</h5><p>A good data set will <strong>contain the same proportion of positive and negative tweets</strong> as <strong><u>a random sample would</u></strong>. Most of the available annotated corpora are <u><strong>artificially</strong></u> balanced just like the data set you’ll use for the assignment. </p>
<p>Howver, in the real tweet stream, positive tweet is sent to occur <strong>more often</strong> than their negative counterparts. One reason for this is that negative tweets might contain content that is banned by the platform or muted by the user such as inappropriate or offensive vocabulary. Assuming that reality behaves as your training corpus, this could <strong>also result in a very optimistic or very pessimistic model——一样影响了prevalence p(pos) p(neg)，进而影响模型</strong></p>
<h4 id="优势-简单快捷"><a href="#优势-简单快捷" class="headerlink" title="优势: 简单快捷"></a>优势: 简单快捷</h4><p>但Naive Bayes依然可以用于<strong>简单的分类问题</strong></p>
<p>It takes a <strong>short time</strong> to train and also has a short prediction time.</p>
<hr>
<p>先说结果：</p>
<h3 id="Training-pipeline-5步"><a href="#Training-pipeline-5步" class="headerlink" title="Training pipeline 5步"></a>Training pipeline 5步</h3><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlr7qj6mxj30yg0u04hx.jpg" alt="朴素贝叶斯pipeline" style="zoom:43%;" />



<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlr8wg82vj311i0di46n.jpg" alt = "training过程总结" style="zoom:30%;" />

<h3 id="学习步骤-本质是naive的-频率-→-概率"><a href="#学习步骤-本质是naive的-频率-→-概率" class="headerlink" title="学习步骤: 本质是naive的 频率 → 概率"></a>学习步骤: 本质是naive的 频率 → 概率</h3><p>Step1 同逻辑斯特回归，计算词频</p>
<p>Step2 根据词频，计算在各类中的<strong><u>条件概率</u></strong> </p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlpxj3b6wj31eo0n6n93.jpg" alt="根据词频计算条件概率" style="zoom:33%;" />



<p>Step3 <strong>同一个</strong>词的正负类<strong>比例相除</strong>，再<strong>各个词的相乘</strong>——最后得到<strong>偏向类</strong>，<strong>以1位界限</strong></p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlq1b1z5qj31gk0ia14g.jpg"  style="zoom:40%;" />

<p>比例为1，则为neutral；大于1，则偏向正类；……</p>
<h4 id="改进1-Laplacian-Smoothing-避免出现概率为0"><a href="#改进1-Laplacian-Smoothing-避免出现概率为0" class="headerlink" title="改进1: Laplacian Smoothing-避免出现概率为0"></a>改进1: Laplacian Smoothing-避免出现概率为0</h4><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlq010yc8j30le0hcwl8.jpg" alt="当词频(概率)为0" style="zoom:33%;" />

<p>因为naive公式，需要各个词在各个类的条件概率的比值，相乘——但如果出现<strong>频率为0</strong>的词，会导致乘法结果无意义</p>
<p>Laplacian Smoothing相当于加了个bias，让<strong>概率转化为接近0的数 而避免了0</strong>。这种转化对于结果影响自然很小</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlovcgbq2j30x608odhw.jpg" style="zoom:33%;" />

<h5 id="Smoothing公式"><a href="#Smoothing公式" class="headerlink" title="Smoothing公式"></a>Smoothing公式</h5><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlowop7gij31gu0jy7e8.jpg" style="zoom:33%;" />



<h4 id="Naive-Bayes-Inference"><a href="#Naive-Bayes-Inference" class="headerlink" title="Naive Bayes Inference"></a>Naive Bayes <u>Inference</u></h4><h5 id="ratio定义"><a href="#ratio定义" class="headerlink" title="ratio定义"></a>ratio定义</h5><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlp0hfq3zj31fi0n0aoy.jpg" style="zoom:33%;" />

<h4 id=""><a href="#" class="headerlink" title=""></a></h4><p>ratio的别名：<strong>likelihood</strong></p>
<h5 id="题外话：Prior-ratio先验分布-——有用，尤其当数据集是unbalanced的"><a href="#题外话：Prior-ratio先验分布-——有用，尤其当数据集是unbalanced的" class="headerlink" title="题外话：Prior ratio先验分布 ——有用，尤其当数据集是unbalanced的"></a>题外话：Prior ratio先验分布 ——有用，尤其当数据集是unbalanced的</h5><h6 id="Why-prior"><a href="#Why-prior" class="headerlink" title="Why prior ?"></a><font color="#dd0000">Why prior ?</font></h6><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlt1seunwj31oo0ce0vk.jpg" style="zoom:53%;" />

<p>如果数据本身unbalanced，则Naive Bayes公式前面必须多乘一项，先验分布的比例！</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlpcysq7tj30pe0bsgpp.jpg" alt="所以正规朴素贝叶斯形式应该如下" style="zoom:40%;" />



<p>课程内的样本数据集是理想的，均匀分布：I haven’t mentioned it till now because in this small example, we have <strong>exactly the same number of</strong> positive and negative tweets, making the ratio one. In this week’s assignments, you’ll have a balanced datasets, so you’ll be working with a ratio of one. </p>
<blockquote>
<p>In the future though, when you’re building your own application, remember that <strong>this term becomes important for unbalanced datasets.</strong> </p>
</blockquote>
<h4 id="改进2-log-likelihood-概率太小数了，取对数方便计算"><a href="#改进2-log-likelihood-概率太小数了，取对数方便计算" class="headerlink" title="改进2: log likelihood-概率太小数了，取对数方便计算"></a>改进2: log likelihood-概率太小数了，取对数方便计算</h4><blockquote>
<p>Carrying out <strong>small number multiplications</strong> runs the risk of <strong>numerical underflow</strong> when the number returned is so small it can’t be stored on the device</p>
</blockquote>
<p>累程 变 <strong>累加</strong></p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlpi83j76j31gs0dejy7.jpg" alt="用log-likelihood ratio后的朴素贝叶斯公式" style="zoom:33%;" />

<p>我们将log-likelihood ratio，新定义为<strong>λ</strong></p>
<h5 id="-1"><a href="#-1" class="headerlink" title=""></a></h5><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlpns2a6mj31h80g2gyg.jpg" alt="0就是界限，为neutral" style="zoom:33%;" />

<p>然后再对<strong>各个λ求和</strong>，如：大于0，则该句子情感为pos类…</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlpqjrj4nj31hm0eigw7.jpg" style="zoom:33%;" />



<h5 id="好处1-重新定义分类界线：从1改成0"><a href="#好处1-重新定义分类界线：从1改成0" class="headerlink" title="好处1: 重新定义分类界线：从1改成0"></a>好处1: 重新定义分类界线：从1改成0</h5><p>即neg类概率更大时 ratio可以为负，负数更直观</p>
<h5 id="好处2-原始ratio的区间长度并不对称，neg类只能取值-0-1-，neg-sentiment程度不明显！用了log就是长度完全对称的区间！"><a href="#好处2-原始ratio的区间长度并不对称，neg类只能取值-0-1-，neg-sentiment程度不明显！用了log就是长度完全对称的区间！" class="headerlink" title="好处2: 原始ratio的区间长度并不对称，neg类只能取值[0,1)，neg sentiment程度不明显！用了log就是长度完全对称的区间！"></a>好处2: 原始ratio的区间<u>长度并不对称</u>，neg类只能<font color="#dd0000">取值[0,1)，neg sentiment程度不明显</font>！用了log就是<u>长度完全对称的区间</u>！</h5><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlptv6i4ij31ca0je46t.jpg" alt="区间的改变" style="zoom:33%;" />



<h3 id="Testing-用于predict"><a href="#Testing-用于predict" class="headerlink" title="Testing: 用于predict"></a>Testing: 用于predict</h3><h4 id="如果测试时，出现模型之前没见到过词，就当neutral！"><a href="#如果测试时，出现模型之前没见到过词，就当neutral！" class="headerlink" title="如果测试时，出现模型之前没见到过词，就当neutral！"></a>如果测试时，出现模型之前没见到过词，就当neutral！</h4><blockquote>
<p>The values that don’t show up in the table <strong>are considered neutral</strong> and don’t contribute anything to this score. The <strong>ML model can only give a score for words it’s seen before.</strong></p>
</blockquote>
<p>别忘了用了log累加时，如果数据不平很 最后得加上prior的log！</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlrtq4ujyj31h00msh1e.jpg" alt="interview这个词没学过，则为neutral" style="zoom:33%;" />



<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghlryf207cj317g0myk0s.jpg" style="zoom:33%;" />



<h3 id="Naive-Bayes的延伸分类应用"><a href="#Naive-Bayes的延伸分类应用" class="headerlink" title="Naive Bayes的延伸分类应用"></a>Naive Bayes的延伸分类应用</h3><p>上面是bayes公式，上下相除<strong>抵消P(tweet)</strong>, 可得下面的公式</p>
<p>下面是之前bayes训练的公式(本身就有 <strong>P(w/pos)的累乘 = P(tweet/pos)</strong>)</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghmvic7kvmj30rk0ec0yt.jpg" alt="该分类模型延伸应用的公式推导" style="zoom:53%;" />

<p>下面左边，就是<strong>模型预测的结果(ratio)</strong>——<font color="#dd0000">这种形式，可以延伸应用到<strong>其他2分类领域</strong></font></p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghmvje5q7nj312c0hi0ym.jpg" alt="延伸领域" style="zoom:35%;" />

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghmwqw0z0ej313k0k6aq1.jpg" alt="消除二分歧义" style="zoom:33%;" />



<h3 id="单靠词频的Naive-Bayes的潜在error"><a href="#单靠词频的Naive-Bayes的潜在error" class="headerlink" title="单靠词频的Naive Bayes的潜在error"></a>单靠<u>词频</u>的Naive Bayes的潜在error</h3><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghmxep6f9cj30ui0buacj.jpg" alt="image-20200811155634232" style="zoom:50%;" />

<h4 id="1-semantic-meaning-lost-in-the-pre-processing-step"><a href="#1-semantic-meaning-lost-in-the-pre-processing-step" class="headerlink" title="1. semantic meaning lost in the pre-processing step"></a>1. <u>semantic meaning lost</u> in the pre-processing step</h4><p>教训：还是务必查看原始句子语义，而不是单纯的移除标点符号和stop words</p>
<h5 id="移除特殊标点-构成了表情，决定了情感"><a href="#移除特殊标点-构成了表情，决定了情感" class="headerlink" title="移除特殊标点(构成了表情，决定了情感)"></a>移除特殊标点(构成了表情，决定了情感)</h5><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghmxj90vh5j30r80a6adu.jpg" alt="表情符号不可移除！" style="zoom:33%;" />



<p>The sad face punctuation in this case is very <strong>important to the sentiment</strong>  because it tells you what’s happening. </p>
<p>But if you’re removing punctuation, then the processed tweet will leave behind only  beloved grandmother, which looks like a very positive tweet. </p>
<h5 id="移除stop-words"><a href="#移除stop-words" class="headerlink" title="移除stop words"></a>移除stop words</h5><p>not这二元180°转义词，<strong>也是stop word！</strong></p>
 <img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghmxn45612j31ea0860z7.jpg" style="zoom:33%;" />

<p>If you remove neutral words like not and this, what you’re left with is the [Good, attitude, close, nice]</p>
<p>From this set of words, any classifier will infer that this is something very positive.</p>
<h4 id="2-word-order-affects-the-meaning-of-a-sentence"><a href="#2-word-order-affects-the-meaning-of-a-sentence" class="headerlink" title="2. word order affects the meaning of a sentence"></a>2. word order affects the meaning of a sentence</h4><p>word order自然是语义的一部分</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghmxor6jelj312k0ciwmh.jpg" style="zoom:33%;" />



<h4 id="3-quirks-怪癖-of-languages-come-naturally-to-humans-but-confuse-models"><a href="#3-quirks-怪癖-of-languages-come-naturally-to-humans-but-confuse-models" class="headerlink" title="3. quirks(怪癖) of languages come naturally to humans but confuse models."></a>3. quirks(怪癖) of languages come naturally to humans but <u>confuse</u> models.</h4><p>Quirk： 人类语言中的 带有sarcasm irony讽刺、euphemism委婉等色彩，adversarial(<strong>恰恰反义、敌对</strong>)性质词</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghmxqfa2p7j31fo0he4ab.jpg" alt="这种反义，属于adversarial" style="zoom:33%;" />

<hr>
<h1 id="2-Word-Vector-和-Vector-Space入门"><a href="#2-Word-Vector-和-Vector-Space入门" class="headerlink" title="2. Word Vector 和 Vector Space入门"></a>2. Word Vector 和 Vector Space入门</h1><p>词向量，向量空间模型</p>
<h2 id="Why-vector-space-形式和应用"><a href="#Why-vector-space-形式和应用" class="headerlink" title="Why vector space? 形式和应用"></a>Why vector space? 形式和应用</h2><h3 id="形式"><a href="#形式" class="headerlink" title="形式"></a>形式</h3><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghmylqhg13j30m805edhp.jpg" style="zoom:43%;" />



<h3 id="应用-底层"><a href="#应用-底层" class="headerlink" title="应用(底层)"></a>应用(底层)</h3><p>Vector space models will </p>
<ol>
<li>验证句子语义的相似性：identify whether the first pair of questions or the second pair <strong>are similar in meaning</strong> even if they do not share the same word 即<strong>identify similarity</strong> for a question answering, paraphrasing, and summarization.</li>
</ol>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghmyakwvu0j319a0j6gw0.jpg"  style="zoom:33%;" />



<ol start="2">
<li><font color="#dd0000"><em>发掘语言中，词之间*</em>关联性<strong></font>: to **<font color="#dd0000">capture dependencies between words</font></strong>——应用很广！！！</li>
</ol>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghmyi6ab4oj31e40iuk6o.jpg" alt="这个可以引用到很多领域，常见如下" style="zoom:45%;" />



<h2 id="共现矩阵"><a href="#共现矩阵" class="headerlink" title="共现矩阵"></a>共现矩阵</h2><h3 id="word-by-word的matrix"><a href="#word-by-word的matrix" class="headerlink" title="word by word的matrix"></a>word by word的matrix</h3><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghmz1fgbtgj31ea0f8n6b.jpg" alt="若词出现在k距离内次数越频繁，则这组词越相关" style="zoom:33%;" />



<h3 id="word-by-doc的"><a href="#word-by-doc的" class="headerlink" title="word by doc的"></a>word by doc的</h3><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnzcssgqnj313s0kgdqr.jpg" alt="在doc库的各种类，出现的频率" style="zoom:33%;" />



<h3 id="引出Vector-Space"><a href="#引出Vector-Space" class="headerlink" title="引出Vector Space"></a>引出Vector Space</h3><p>这些<strong><font color="#dd0000">有了维度</font>的</strong>数据，就可以<font color="#dd0000"><strong>放入vector space</strong>， 进行相似度分析</font></p>
<p>然后可以看成N-维向量(N为词的数量)，通过比较<strong>向量的”相似性“指标，如距离</strong>——得出句子/语料的相似性**</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnzi90xuuj31ei0ligyp.jpg" style="zoom:30%;" />



<h4 id="vector-space的应用：挖掘word-analogies"><a href="#vector-space的应用：挖掘word-analogies" class="headerlink" title="vector space的应用：挖掘word analogies"></a>vector space的应用：挖掘word analogies</h4><p><strong>infer unknown relations</strong> among words</p>
<h5 id="如通过词已知的关系，推导出，词之间相似但未知的关系"><a href="#如通过词已知的关系，推导出，词之间相似但未知的关系" class="headerlink" title="如通过词已知的关系，推导出，词之间相似但未知的关系"></a>如通过词已知的关系，推导出，<u>词之间相似但未知的关系</u></h5><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gho0me9qq5j30zy0jgwn9.jpg" alt="推测未知的首都" style="zoom:33%;" />





<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gho0nh4gpxj31hk0j6ajs.jpg" alt="用向量减法；再在[10,4]处找，相似指标最大的向量" style="zoom:33%;" />





<h4 id="指标1：Euclidean-distance-欧几里得距离❌"><a href="#指标1：Euclidean-distance-欧几里得距离❌" class="headerlink" title="指标1：Euclidean distance 欧几里得距离❌"></a>指标1：Euclidean distance 欧几里得距离❌</h4><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnzmivjmhj31ck0kgn7q.jpg" style="zoom:40%;" />



<p>Generalize到更高维的</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnzny5azlj313m06ygnh.jpg" alt="该公式也是向量的norm，向量/矩阵的长度或大小" style="zoom:40%;" />



<h4 id="指标2：cosine-similarity✅"><a href="#指标2：cosine-similarity✅" class="headerlink" title="指标2：cosine similarity✅"></a>指标2：cosine similarity✅</h4><p>欧几里得距离的缺点：明显<strong>会受到corpus size的影响</strong>——<strong>导致vector size</strong>长短不一，影响判断</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghnzy5kjw3j31g20nqwsh.jpg" alt="food和农业关联更大，但因food语料库太小，欧几里得误判history关系更大" style="zoom:50%;" />





<h5 id="cosine-similarity"><a href="#cosine-similarity" class="headerlink" title="cosine similarity"></a>cosine similarity</h5><p>即向量的<strong>点积</strong>公式:   多考虑了<strong>语料的大小，即向量长度</strong></p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gho04e04nij30n80b8wgg.jpg" alt="点积" style="zoom:33%;" />

<p>这和向量的”相似度“<strong>有何关联</strong>？</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gho07dveoxj31fe0hwn4x.jpg" alt="0-90°的夹角，也对相似度有影响" style="zoom:33%;" />



<h3 id="word-embeddings-词嵌入-向量"><a href="#word-embeddings-词嵌入-向量" class="headerlink" title="word embeddings 词嵌入(向量)"></a><font color="#dd0000">word embeddings 词嵌入</font>(向量)</h3><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghp2rgex4zj31p005mwh8.jpg" alt="word represents by vector" style="zoom:53%;" />

<p>….</p>
<hr>
<h3 id="PCA-高纬数据的降维"><a href="#PCA-高纬数据的降维" class="headerlink" title="PCA: 高纬数据的降维"></a>PCA: 高纬数据的降维</h3><p>a <strong>statistical technique</strong></p>
<h4 id="目的-方便可视化"><a href="#目的-方便可视化" class="headerlink" title="目的: 方便可视化"></a>目的: 方便可视化</h4><h5 id="降维到2D方便可视化，来找关系"><a href="#降维到2D方便可视化，来找关系" class="headerlink" title="降维到2D方便可视化，来找关系"></a>降维到2D方便可视化，来找关系</h5><p><strong>Word embeaddings</strong> end up having <strong>vectors in very, very high dimensions</strong>.</p>
<p>PCA：a way to <strong>reduce the dimension of these vectors to two dimensions so you can plot it on an X-Y axis, 2D plot.</strong> </p>
<p>helpful for <u><strong>visualizing</strong></u> your data to check if your representation is <strong><u>capturing relationships</u> among words</strong></p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghp7blx33uj31po092adg.jpg" alt=""></p>
<h4 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h4><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gho4f0u4nrj31hu0j2drh.jpg" style="zoom:33%;" />



<p>需要：向量的<strong>特征值和特征向量</strong></p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gho6suirinj317u074goy.jpg" style="zoom:33%;" />



<p>为什么要不相关的feature? 因为<strong>自然语言文本总是上下文相关的</strong>，所以feature之间总有一定相关性，</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gho6ula7l9j31io0ne12y.jpg" alt="Step1 生成uncorrelated features" style="zoom:33%;" />

<p>注：PCA works better <strong>if the data is <u>centered</u></strong></p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gho6veh9o8j31cu0guwo4.jpg" alt="Step2 通过和特征向量的点积，求出压缩后的向量" style="zoom:33%;" />

<hr>
<h1 id="3-词向量Task-机器翻译和相似doc搜索"><a href="#3-词向量Task-机器翻译和相似doc搜索" class="headerlink" title="3. 词向量Task: 机器翻译和相似doc搜索"></a>3. 词向量Task: 机器翻译和相似doc搜索</h1><h2 id="-2"><a href="#-2" class="headerlink" title=""></a></h2><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghp8c3q9suj31bw0h2n5y.jpg" alt="相关知识" style="zoom:50%;" />



<h2 id="Task-翻译"><a href="#Task-翻译" class="headerlink" title="Task: 翻译"></a>Task: 翻译</h2><p><a href="https://kennyng-19.github.io/Kenny_Ng.github.io/2020/01/29/NLP-intro/#1-case-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91" target="_blank" rel="noopener">一种实现：维特比算法</a></p>
<p>另一种实现：<strong>已知两种语言的word embeddings</strong>，通过<strong>寻找<u>transform matrix</u></strong>，找到转换后 <strong>目标语言中最相似的word vector</strong>——我们称该过程为<strong>“align word vectors”</strong></p>
<h4 id="Step1-Transfor-vector-by-matrix"><a href="#Step1-Transfor-vector-by-matrix" class="headerlink" title="Step1: Transfor vector by matrix"></a>Step1: Transfor vector by <u>matrix</u></h4><p>find <strong>a transformation matrix</strong> from English to French vector space embeddings. </p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghp9x50omjj31e40hadnt.jpg" alt ="align word vectors" style="zoom:33%;" />



<p>Such a transformation matrix is <strong>a matrix that <font color="#dd0000">rotates and scales vector spaces</font></strong>——回忆《<strong>线性代数的本质</strong>》</p>
<h4 id="然后怎么计算该矩阵呢？还是优化问题"><a href="#然后怎么计算该矩阵呢？还是优化问题" class="headerlink" title="然后怎么计算该矩阵呢？还是优化问题"></a><strong>然后怎么计算该矩阵呢？还是优化问题</strong></h4><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghpa0ho7c8j30ya0gk78h.jpg" alt="还是梯度下降，这不过这次是矩阵的" style="zoom:50%;" />



<h4 id="补充notation-Frobenius范数-即矩阵元素的平方和的开方"><a href="#补充notation-Frobenius范数-即矩阵元素的平方和的开方" class="headerlink" title="补充notation-Frobenius范数: 即矩阵元素的平方和的开方"></a>补充notation-Frobenius范数: 即矩阵元素的平方和的开方</h4><p>F范数是<strong>针对矩阵而言</strong>的，具体定义可以<strong>类比向量的L2范数</strong></p>
<img src="https://pic3.zhimg.com/80/ded8e501d6d54eaf3d218491423380df_1440w.jpg?source=1940ef5c" alt="F范数" style="zoom:80%;" />

<p>当然在ML中，为了简化计算(因为范数只是用于<strong><u>最优化</u></strong>)，可以<strong>不开方而是保留平方</strong></p>
<p>所以保留开方后，Loss函数最终形式为：</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghpa22ro8jj30z00b876y.jpg" alt="Loss函数最终形式" style="zoom:33%;" />





<h5 id="拓展，3-main-vector-transformations的几何意义"><a href="#拓展，3-main-vector-transformations的几何意义" class="headerlink" title="拓展，3 main vector transformations的几何意义"></a>拓展，3 main vector transformations的几何意义</h5><p>(更多，请回忆《<strong>线性代数的本质</strong>》)</p>
<ul>
<li>Scaling</li>
<li>Translatio</li>
<li>Rotation</li>
</ul>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghp9qtx6x8j313f0u0dr9.jpg" alt="关于施加rotation矩阵的结论" style="zoom:50%;" />



<h4 id="Step-2-寻找最相似的几个翻译结果by-KNN"><a href="#Step-2-寻找最相似的几个翻译结果by-KNN" class="headerlink" title="Step 2: 寻找最相似的几个翻译结果by KNN"></a>Step 2: 寻找最相似的<u>几个</u>翻译结果by <u>KNN</u></h4><p>因为word embedding空间不一定有，和matrix转换的<strong>结果数值一模一样的词向量</strong>，且存在<u>近义词</u>——所以一般是会输出<strong>几个最近似</strong>的词向量，供选择。这里会用到KNN算法</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghpa5okk64j314g0fm0zw.jpg" style="zoom:30%;" />

<h4 id="改进版-faster-approximate-KNN"><a href="#改进版-faster-approximate-KNN" class="headerlink" title="改进版 faster approximate KNN"></a>改进版 faster <u>approximate</u> KNN</h4><h5 id="启发思路：空间划分"><a href="#启发思路：空间划分" class="headerlink" title="启发思路：空间划分"></a>启发思路：空间划分</h5><p>(下图只是<strong>简单的2D空间</strong>) <strong>slice the space <u>into regions</u></strong>: you could <strong>search just <u>within</u> those regions</strong>. When you think about organizing subsets of a dataset efficiently, you may think about placing your data <strong>into <u>buckets</u></strong></p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghqbl9ocp8j31220jywwe.jpg" style="zoom:33%;" />



<p>If you think about buckets, then you’ll definitely want to think about <font color="#dd0000"><strong><u>hash tables</u></strong></font>.</p>
<h5 id="提升KNN，处理高维数据的效率：Locality-Sensitive-Hashing"><a href="#提升KNN，处理高维数据的效率：Locality-Sensitive-Hashing" class="headerlink" title="提升KNN，处理高维数据的效率：Locality Sensitive Hashing"></a>提升KNN，处理<u>高维数据</u>的效率：Locality Sensitive Hashing</h5><p>本质是 a <strong>hash function</strong>, to be locality sensitive; an <strong><a href="https://en.wikipedia.org/wiki/Locality-sensitive_hashing" target="_blank" rel="noopener">algorithmic technique</a></strong> that hashes <strong>similar input items into the same “buckets” with <u>high probability</u></strong>——所以说是一种<strong>近似法, “approximate”</strong></p>
<p>白话定义：把vector根据在<strong>vector space中的距离足够近</strong>的<strong>分到一起</strong>，的Hashing方法</p>
<blockquote>
<p>Locality is another word for location, sensitive is another word for caring </p>
<p>This is kNN in simple terms: You have a labelled dataset and now you are trying to label a new data point. Find the k nearest data points from your labelled dataset to the new point. The majority vote among the k nearest neighbors is the label of the new point. Add the new point and it’s label to your dataset</p>
<p>One of the <strong>biggest problems with kNN 处理高维数据时</strong> is that <strong>常规的暴力法下，for each new data point, you have to calculate its distance from all existing points in your dataset.</strong> The LSH technique, differing from <a href="https://en.wikipedia.org/wiki/Hash_function" target="_blank" rel="noopener">conventional hashing techniques</a> in that hash collisions are maximized, not minimized,  can be seen as a way to <strong>reduce the dimensionality of high-dimensional data</strong>; high-dimensional input items can be <strong>reduced to low-dimensional versions while preserving <u>relative distances</u> between items</strong>. And this problem is what LSH is <strong>trying to solve</strong>.</p>
</blockquote>
<p>So locality sensitive hashing is a <strong>hashing method</strong> that’s <strong>cares very deeply about assigning items based on where they’re <u>located in vector space</u></strong>.</p>
<h6 id="核心：Multiplanes-hash-functions"><a href="#核心：Multiplanes-hash-functions" class="headerlink" title="核心：Multiplanes hash functions"></a>核心：<u><strong>Multiplanes hash functions</strong></u></h6><blockquote>
<p>In order to divide your vector space <strong>into <u>manageable</u> regions</strong>, you’ll want to use <strong><u>more than one plane</u></strong>. Based on the idea of <strong>numbering every single region</strong> that is <strong>formed by the <u>intersection of n planes</u>.</strong></p>
</blockquote>
<p><a href="https://kennyng-19.github.io/Kenny_Ng.github.io/2020/07/25/ML-concepts-memorize/#6-ml理论中常见的超平面概念" target="_blank" rel="noopener">思路</a>：每一个plane，实际就是定义一个<strong>法向量</strong></p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghrkcqi8smj313602kjsl.jpg" style="zoom:33%;" />

<p>几何上，you have multiple planes and it helps us to divide the vector space into smaller sub regions. But you <strong>want to have a single hash value</strong> to know <strong>which bucket to assign the vectoring</strong>. You do this by <strong>combining the signals from all the planes</strong> into a single hash value.</p>
<p>那么定义一组plane就等于一组法向量 output value is a <strong>combination of the side of the plane</strong> where the vector is localized with respect to the collection of planes.</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghrkdjszw6j30zu0lygq0.jpg" style="zoom:33%;" />



<p>Locality Sensitive Hashing<strong>最终计算公式</strong>：看sign定boolean值h，再用2的幂次求和公式</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghrkhg1by3j312a0k0k0i.jpg" style="zoom:40%;" />



<h6 id="注意-因为是随机生成的法向量-plane，请重复多次得到更合理的结果-make-sets-of-random-planes"><a href="#注意-因为是随机生成的法向量-plane，请重复多次得到更合理的结果-make-sets-of-random-planes" class="headerlink" title="注意: 因为是随机生成的法向量-plane，请重复多次得到更合理的结果 make sets of random planes"></a>注意: 因为是随机生成的法向量-plane，请重复多次得到更合理的结果 make sets of <strong>random planes</strong></h6><p>You will make <u>multiple</u> sets of <strong><u>random planes</u></strong> in order to make the approximate nearest neighbors <strong>more accurate.</strong></p>
<h2 id="Task-相似doc搜索"><a href="#Task-相似doc搜索" class="headerlink" title="Task: 相似doc搜索"></a>Task: 相似doc搜索</h2><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghp89bzp7ej31e00bgq9h.jpg" style="zoom:33%;" />

<p>同理用fast KNN</p>
<p>虽然doc的表示和word的vector表示不完全相同，但doc也是word组成——可以用word embedding中存在的word vector值的<strong>累加</strong>，表示</p>
<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghqhe1yls3j30zy0my7ai.jpg" alt="累加word vector的embedding值" style="zoom:33%;" />



<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ghqhihbgq4j310k0gw4br.jpg" alt="拆分doc成word, 用embedding中存在的word vector累加" style="zoom:33%;" />

<p>有了所有doc的vector，剩下的寻找<strong>近似目标</strong>，就和上述KNN过程一样了…</p>

            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/Kenny_Ng.github.io/about" rel="external nofollow noreferrer">Kenny Ng</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://yoursite.com/Kenny_Ng.github.io/2020/08/08/NLP-DeepLearning-ai/">http://yoursite.com/Kenny_Ng.github.io/2020/08/08/NLP-DeepLearning-ai/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="/Kenny_Ng.github.io/about" target="_blank">Kenny Ng</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/Kenny_Ng.github.io/tags/NLP/">
                                    <span class="chip bg-color">NLP</span>
                                </a>
                            
                                <a href="/Kenny_Ng.github.io/tags/math/">
                                    <span class="chip bg-color">math</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/Kenny_Ng.github.io/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/Kenny_Ng.github.io/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/Kenny_Ng.github.io/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/Kenny_Ng.github.io/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;Current
            </div>
            <div class="card">
                <a href="/Kenny_Ng.github.io/2020/08/08/NLP-DeepLearning-ai/">
                    <div class="card-image">
                        
                        
                        <img src="/Kenny_Ng.github.io/medias/featureimages/0.jpg" class="responsive-img" alt="DeepLearning.ai新课-NLP-Course1">
                        
                        <span class="card-title">DeepLearning.ai新课-NLP-Course1</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            1. Task: text classification法1: Logsitc回归模型法2: 纯靠词频的Naive Bayes模型
Naive Bayes is an example of supervised machine learni
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-08-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Kenny Ng
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/Kenny_Ng.github.io/tags/NLP/">
                        <span class="chip bg-color">NLP</span>
                    </a>
                    
                    <a href="/Kenny_Ng.github.io/tags/math/">
                        <span class="chip bg-color">math</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/Kenny_Ng.github.io/2020/07/25/AI4m-DeepLearning-ai/">
                    <div class="card-image">
                        
                        
                        <img src="/Kenny_Ng.github.io/medias/featureimages/11.jpg" class="responsive-img" alt="DeepLearning.ai5月新课-AI4Medicince笔记">
                        
                        <span class="card-title">DeepLearning.ai5月新课-AI4Medicince笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            1. Course1-AI for Medical Diagnosis(诊断)I. ML进阶，可能遇到的更实际的进阶问题：3个

a. 训练数据分布-Class imbalance问题如 实际在收集要拿來做DL的医学数据時，常识是 正常的非
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2020-07-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Kenny Ng
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/Kenny_Ng.github.io/tags/ML/">
                        <span class="chip bg-color">ML</span>
                    </a>
                    
                    <a href="/Kenny_Ng.github.io/tags/CV/">
                        <span class="chip bg-color">CV</span>
                    </a>
                    
                    <a href="/Kenny_Ng.github.io/tags/math/">
                        <span class="chip bg-color">math</span>
                    </a>
                    
                    <a href="/Kenny_Ng.github.io/tags/advancedML/">
                        <span class="chip bg-color">advancedML</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/Kenny_Ng.github.io/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/Kenny_Ng.github.io/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/Kenny_Ng.github.io/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/Kenny_Ng.github.io/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->

<style type="text/css">
code[class*="language-"], pre[class*="language-"] { white-space: pre !important; }
</style>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/Kenny_Ng.github.io/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/Kenny_Ng.github.io/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="5200611191"
                   fixed='true'
                   autoplay='true'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.5'
                   list-folded='false'
        >
        </meting-js>
    </div>
</div>

<script src="/Kenny_Ng.github.io/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2019</span>
            <a href="/Kenny_Ng.github.io/about" target="_blank">Kenny Ng</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/KennyNg-19" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:wuyuhao2019@126.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=836316155" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 836316155" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/Kenny_Ng.github.io/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/Kenny_Ng.github.io/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/Kenny_Ng.github.io/search.xml", 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/Kenny_Ng.github.io/libs/materialize/materialize.min.js"></script>
    <script src="/Kenny_Ng.github.io/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/Kenny_Ng.github.io/libs/aos/aos.js"></script>
    <script src="/Kenny_Ng.github.io/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/Kenny_Ng.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/Kenny_Ng.github.io/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/Kenny_Ng.github.io/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/Kenny_Ng.github.io/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    

    

    
    <script src="/Kenny_Ng.github.io/libs/instantpage/instantpage.js" type="module"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    

</body>

</html>
